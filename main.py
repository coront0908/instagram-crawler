"""
main.py
Instagramã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆå·¡å›ã®å…¨ä½“åˆ¶å¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆå®Ÿè¡Œã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®è²¬ä»»ã‚’æŒã¤ï¼š
1. .envã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿
2. Instagramã¸ãƒ­ã‚°ã‚¤ãƒ³ã—ã€æŒ‡å®šã‚¿ã‚°ã®æŠ•ç¨¿ã‚’å·¡å›
3. å„æŠ•ç¨¿ã‹ã‚‰æ¥½å¤©ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆURLã‚’æŠ½å‡ºãƒ»æ­£è¦åŒ–
4. URLã®ç™»å ´å›æ•°ã‚’é›†è¨ˆã—ã€å•†å“åã‚’å–å¾—
5. å•†å“å / å›æ•° / URL ã§æ§‹æˆã•ã‚ŒãŸCSVã‚’å‡ºåŠ›
6. å…¨å‡¦ç†ã®ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
"""

from dotenv import load_dotenv
from browser.instagram_login import login_and_get_driver
from browser.fetch_post_links import get_post_links
from browser.fetch_post_texts import get_post_texts
from parser.extract_urls import extract_affiliate_urls
from parser.normalize_urls import normalize_url
from parser.fetch_titles import add_product_titles  # âœ… å•†å“åå–å¾—ã‚¹ãƒ†ãƒƒãƒ—
from aggregator.count_urls import count_normalized_urls
from aggregator.export_to_csv import export_csv
from util.logger import setup_logger

import os
from datetime import datetime
from pathlib import Path

# --- åˆæœŸè¨­å®šï¼šç’°å¢ƒå¤‰æ•°ãƒ»ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— ---
load_dotenv()
USERNAME = os.getenv("INSTAGRAM_USER")
PASSWORD = os.getenv("INSTAGRAM_PASS")
TARGET_TAG = os.getenv("TARGET_TAG", "æ¥½å¤©room")
MAX_POSTS = int(os.getenv("MAX_POSTS", 5))

now = datetime.now().strftime("%Y%m%d_%H%M%S")

# --- ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ– ---
log_dir = Path("log")
log_dir.mkdir(parents=True, exist_ok=True)
log = setup_logger(log_dir / f"log_{now}.txt")
log(f"ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")

# --- Instagramãƒ­ã‚°ã‚¤ãƒ³ ---
log("ğŸš€ Instagramãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
driver = login_and_get_driver(USERNAME, PASSWORD, log)

try:
    # --- ã‚¿ã‚°ãƒšãƒ¼ã‚¸ã®æŠ•ç¨¿ãƒªãƒ³ã‚¯ã‚’å–å¾— ---
    log("ğŸ“Œ ã‚¿ã‚°å·¡å›ã‚’é–‹å§‹ã—ã¾ã™")
    post_links = get_post_links(driver, TARGET_TAG, log, max_posts=MAX_POSTS)

    # --- å„æŠ•ç¨¿ãƒšãƒ¼ã‚¸ã‹ã‚‰æœ¬æ–‡ã‚’å–å¾— ---
    log("ğŸ“Œ å„æŠ•ç¨¿ã®æœ¬æ–‡ã‚’å–å¾—ã—ã¾ã™")
    post_texts = get_post_texts(driver, post_links, max_count=MAX_POSTS)

    # --- æœ¬æ–‡ã‹ã‚‰æ¥½å¤©ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆURLã‚’æŠ½å‡ºãƒ»æ­£è¦åŒ– ---
    all_urls = []
    for i, post in enumerate(post_texts):
        log(f"ğŸ” [{i+1}/{len(post_texts)}] æŠ•ç¨¿æœ¬æ–‡ã‹ã‚‰ãƒªãƒ³ã‚¯æŠ½å‡ºä¸­")

        # â­ æœ¬æ–‡ã®å…ˆé ­ã ã‘ç¢ºèªãƒ­ã‚°ï¼ˆå¤šã™ãã‚‹ã¨ç…©é›‘ãªã®ã§80æ–‡å­—åˆ¶é™ï¼‰
        log(f"ğŸ“ æœ¬æ–‡æŠœç²‹: {post['text'][:80].replace('\n', ' ')}...")

        urls = extract_affiliate_urls(post["text"])
        normed = [normalize_url(u) for u in urls]
        
        if normed:
            log(f"âœ… æŠ½å‡ºã•ã‚ŒãŸãƒªãƒ³ã‚¯: {normed}")
        else:
            log("â„¹ï¸ å•†å“ãƒªãƒ³ã‚¯ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        all_urls.extend(normed)

    # --- URLã”ã¨ã®ç™»å ´å›æ•°ã‚’é›†è¨ˆ ---
    log("ğŸ“Š å•†å“ãƒªãƒ³ã‚¯ã®å‡ºç¾å›æ•°ã‚’é›†è¨ˆã—ã¾ã™")
    count_df = count_normalized_urls(all_urls, log)

    # --- å„URLã‹ã‚‰å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã—ã¦åˆ—è¿½åŠ  ---
    log("ğŸ“Œ å„URLã‹ã‚‰å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã—ã¾ã™")
    count_df = add_product_titles(count_df, log)

    # --- CSVã«ä¿å­˜ï¼ˆæˆæœç‰©å‡ºåŠ›ï¼‰---
    log("ğŸ’¾ çµæœã‚’CSVã¨ã—ã¦ä¿å­˜ã—ã¾ã™")
    export_csv(count_df, now, log)

except Exception as e:
    log(f"ğŸ’¥ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

finally:
    # --- ãƒ‰ãƒ©ã‚¤ãƒçµ‚äº†å‡¦ç† ---
    driver.quit()
    log("ğŸ›‘ ãƒ–ãƒ©ã‚¦ã‚¶ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
    log("ğŸ‰ å…¨å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
