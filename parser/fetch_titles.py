import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

def fetch_title_from_url(url: str, log=None) -> str:
    """
    å˜ä¸€URLã«å¯¾ã—ã¦å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã™ã‚‹
    å„ªå…ˆé †ä½ï¼š<meta property="og:title"> â†’ <title>
    """

    if log:
        log(f"ğŸŸ¡ fetch_title_from_url() â–¶ é–‹å§‹ URL: {url}")
        log("ğŸŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡æº–å‚™...")

    try:
        res = requests.get(url, timeout=10)

        # --- å¿µã®ãŸã‚æ–‡å­—ã‚³ãƒ¼ãƒ‰è£œæ­£ ---
        res.encoding = res.apparent_encoding

        # --- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ç¢ºèª ---
        if log:
            log(f"ğŸ“¡ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {res.status_code}")
        if res.status_code != 200:
            if log:
                log(f"âš ï¸ HTTPã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆcode={res.status_code}ï¼‰")
                # å¿œç­”å†…å®¹ã®ä¸€éƒ¨è¡¨ç¤ºï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–ä»˜ãï¼‰
                snippet = res.text[:100].replace("\n", " ").strip()
                log(f"ğŸ§¾ HTMLæŠœç²‹: {snippet} ...")
            return "ã‚¿ã‚¤ãƒˆãƒ«å–å¾—å¤±æ•—"

        # --- HTMLãƒ‘ãƒ¼ã‚¹ ---
        soup = BeautifulSoup(res.text, "html.parser")

        # --- og:title æŠ½å‡º ---
        og_tag = soup.find("meta", property="og:title")
        if og_tag:
            og_title = og_tag.get("content", "").strip()
            if og_title:
                if log:
                    log(f"âœ… og:title æŠ½å‡ºæˆåŠŸ â–¶ {og_title}")
                return og_title
            else:
                if log:
                    log("âš ï¸ og:titleã‚¿ã‚°ã¯å­˜åœ¨ã™ã‚‹ãŒä¸­èº«ãŒç©º")

        # --- fallback: titleã‚¿ã‚° ---
        if soup.title:
            if soup.title.string:
                title_text = soup.title.string.strip()
                if title_text:
                    if log:
                        log(f"âœ… <title> ã‚¿ã‚°ã‹ã‚‰æŠ½å‡º â–¶ {title_text}")
                    return title_text
                else:
                    if log:
                        log("âš ï¸ <title> ã‚¿ã‚°ãŒç©º")
            else:
                if log:
                    log("âš ï¸ <title> ã‚¿ã‚°ã«æ–‡å­—åˆ—ãŒå­˜åœ¨ã—ãªã„")
        else:
            if log:
                log("âš ï¸ <title> ã‚¿ã‚°è‡ªä½“ãŒå­˜åœ¨ã—ãªã„")

        return "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜"

    except Exception as e:
        if log:
            log(f"âŒ ä¾‹å¤–ç™ºç”Ÿ â–¶ {type(e).__name__}: {e}")
        return "å–å¾—ã‚¨ãƒ©ãƒ¼"


def add_product_titles(df: pd.DataFrame, log) -> pd.DataFrame:
    """
    é›†è¨ˆæ¸ˆã¿URLã®DataFrameã«å¯¾ã—ã¦ã€å•†å“ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã‚’è¿½åŠ ã™ã‚‹

    Parameters:
        df (pd.DataFrame): 'å•†å“ID'ï¼ˆ=URLï¼‰ã¨ 'ç™»å ´å›æ•°' ã‚’å«ã‚€DataFrame
        log (function): ãƒ­ã‚°å‡ºåŠ›ç”¨é–¢æ•°

    Returns:
        pd.DataFrame: 'å•†å“å' åˆ—ã‚’è¿½åŠ ã—ãŸDataFrameï¼ˆåˆ—é †ï¼šå•†å“å / ç™»å ´å›æ•° / å•†å“IDï¼‰
    """

    titles = []
    total = len(df)

    log(f"ğŸ“Œ å•†å“ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆå…¨ {total} ä»¶ï¼‰")

    for i, row in df.iterrows():
        url = row["å•†å“ID"]
        log(f"\nğŸ”— [{i+1}/{total}] å¯¾è±¡URL: {url}")

        title = fetch_title_from_url(url, log)
        log(f"ğŸ“ ã‚¿ã‚¤ãƒˆãƒ«çµæœ: {title}")

        time.sleep(1.2)  # é€šä¿¡é–“éš”ç¢ºä¿
        titles.append(title)

    df["å•†å“å"] = titles
    df = df[["å•†å“å", "ç™»å ´å›æ•°", "å•†å“ID"]]  # åˆ—é †èª¿æ•´

    log("âœ… å•†å“ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã®è¿½åŠ ãŒå®Œäº†ã—ã¾ã—ãŸ")
    return df
